{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRi0kGyuFr3fdr6vhPL+//",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cinquecentoandrey/transformers/blob/main/%D0%9F%D1%80%D0%B8%D0%BC%D0%B5%D1%80%D1%8B_%D0%A2%D1%80%D0%B0%D0%BD%D1%81%D1%84%D0%BE%D1%80%D0%BC%D0%B5%D1%80%D1%8B%2BGradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "seZWFMZc8_Yr",
        "outputId": "5d047de4-db34-4c57-9784-9c219e3984b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.29.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "id": "0G6XpiAu9Hvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Пример 1. Анализ тональности текста**"
      ],
      "metadata": {
        "id": "LXbgv2zKDX8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\n",
        "    \"sentiment-analysis\",  # Тип задачи - анализ тональности\n",
        "    model=\"cointegrated/rubert-tiny2-cedr-emotion-detection\",  # Модель для русского языка\n",
        "    tokenizer=\"cointegrated/rubert-tiny2-cedr-emotion-detection\"  # Соответствующий токенизатор\n",
        ")\n",
        "\n",
        "# Создаем словарь для перевода эмоций на русский\n",
        "emotion_map = OrderedDict([\n",
        "    ('neutral', \"Нейтральный\"),\n",
        "    ('joy', \"Радость\"),\n",
        "    ('sadness', \"Грусть\"),\n",
        "    ('surprise', \"Удивление\"),\n",
        "    ('fear', \"Страх\"),\n",
        "    ('anger', \"Злость\"),\n",
        "    ('no_emotion', \"Безразлично\")\n",
        "])\n",
        "\n",
        "# Основная функция для анализа текста\n",
        "def analyze_sentiment(text):\n",
        "    if not text.strip():\n",
        "        return \"Пожалуйста, введите текст для анализа\"\n",
        "\n",
        "    try:\n",
        "        # Ограничиваем длину текста для стабильности работы модели\n",
        "        text = text[:512]\n",
        "\n",
        "        # Получаем результат от модели (возвращает список, берем первый элемент)\n",
        "        result = classifier(text)[0]\n",
        "\n",
        "        # Преобразуем метку эмоции на русский\n",
        "        emotion_label = result['label']\n",
        "        emotion_ru = emotion_map.get(emotion_label, emotion_label)\n",
        "        score = result['score']  # Уверенность модели\n",
        "\n",
        "        # Создаем визуальный прогресс-бар из emoji\n",
        "        filled_squares = int(score * 10)  # Переводим вероятность в 10-балльную шкалу\n",
        "        progress_bar = \"🟩\" * filled_squares + \"⬜\" * (10 - filled_squares)\n",
        "\n",
        "        return f\"\"\"\n",
        "        <div style='font-family: Arial; border-left: 4px solid #000000 ; padding-left: 12px;'>\n",
        "            <div style='font-size: 20px; font-weight: bold; color: #000000 ; margin-bottom: 8px;'>\n",
        "                {emotion_ru}\n",
        "            </div>\n",
        "            <div style='font-size: 16px; margin-bottom: 12px;'>\n",
        "                Уверенность: {score:.0%}\n",
        "            </div>\n",
        "            <div style='font-size: 24px; letter-spacing: 2px;'>\n",
        "                {progress_bar}\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    except Exception as e:\n",
        "        return f\"<div style='color: #FF5722;'>Произошла ошибка: {str(e)}</div>\"\n",
        "\n",
        "# Создаем интерфейс\n",
        "iface = gr.Interface(\n",
        "    fn=analyze_sentiment,  # Функция для обработки ввода\n",
        "\n",
        "    # Настраиваем поле ввода текста\n",
        "    inputs=gr.Textbox(\n",
        "        lines=5,  # Высота текстового поля (5 строк)\n",
        "        placeholder=\"Введите текст...\",  # Подсказка внутри поля\n",
        "        label=\"Текст для анализа\"  # Надпись над полем ввода\n",
        "    ),\n",
        "\n",
        "    # Настраиваем вывод (поддерживаем HTML-разметку)\n",
        "    outputs=gr.HTML(label=\"Результат анализа тональности\"),\n",
        "\n",
        "    # Заголовок интерфейса\n",
        "    title=\"Анализатор тональности текста\",\n",
        "\n",
        "    # Примеры для быстрого тестирования\n",
        "    examples=[\n",
        "        [\"Это просто потрясающе!\"],\n",
        "        [\"Неуд за сессию это не катастрофа.\"],\n",
        "        [\"Сегодня обычный день.\"],\n",
        "        [\"Технологии искусственного интеллекта развиваются стремительно.\"]\n",
        "    ],\n",
        "\n",
        "    # Отключаем кнопку \"Flag\" (не используем систему отчетов)\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "# Запускаем веб-интерфейс\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "NCkaezEb9p28",
        "outputId": "7df88ff2-4e62-4166-d1cb-d789298904f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://492761f4a006a2d024.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://492761f4a006a2d024.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qUxst2gzDWzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Пример 2. Генерация текста**\n",
        "В данном задание можно поэкспериментировать с настройками дополнительных параметров - температурой, кол-вом beam'ов, top-p (разнообразием), чтобы оценить как меняется сгенерированный текст."
      ],
      "metadata": {
        "id": "KZQYCd7VDouS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"sberbank-ai/rugpt3large_based_on_gpt2\",\n",
        "    device=\"cpu\"\n",
        ")\n",
        "\n",
        "def generate_text(prompt, max_length, temperature, top_p, num_beams):\n",
        "    try:\n",
        "        results = generator(\n",
        "            prompt,\n",
        "            max_length=max_length,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            num_beams=num_beams,\n",
        "            do_sample=True,\n",
        "            no_repeat_ngram_size=2,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        generated_text = results[0][\"generated_text\"]\n",
        "\n",
        "        highlighted_text = generated_text.replace(\n",
        "            prompt,\n",
        "            f\"<span style='color: #4CAF50; font-weight: bold;'>{prompt}</span>\"\n",
        "        ) if prompt else generated_text\n",
        "\n",
        "        return f\"\"\"\n",
        "        <div style='font-family: Arial; line-height: 1.6; border-left: 4px solid #4CAF50; padding-left: 15px;'>\n",
        "            {highlighted_text}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    except Exception as e:\n",
        "        return f\"<div style='color: red;'>Ошибка генерации: {str(e)}</div>\"\n",
        "\n",
        "# Создаем интерфейс\n",
        "iface = gr.Interface(\n",
        "    # Основная функция обработки (должна принимать столько аргументов, сколько элементов в inputs)\n",
        "    fn=generate_text,\n",
        "\n",
        "    # Список входных элементов интерфейса\n",
        "    inputs=[\n",
        "        # Текстовое поле для промпта\n",
        "        gr.Textbox(\n",
        "            lines=3,  # Начальная высота в 3 строки\n",
        "            placeholder=\"Введите начало текста или тему для генерации...\",  # Подсказка в пустом поле\n",
        "            label=\"Промпт\",  # Надпись над полем ввода\n",
        "            max_lines=5  # Максимальное количество строк при расширении\n",
        "        ),\n",
        "\n",
        "        # Слайдер для контроля длины текста\n",
        "        gr.Slider(\n",
        "            minimum=20,  # Минимальное значение\n",
        "            maximum=300,  # Максимальное значение\n",
        "            value=100,  # Значение по умолчанию\n",
        "            step=10,  # Шаг изменения\n",
        "            label=\"Максимальная длина\"  # Подпись слайдера\n",
        "        ),\n",
        "\n",
        "        # Слайдер для температуры (контроль случайности)\n",
        "        gr.Slider(\n",
        "            0.1, 1.5,  # Диапазон значений\n",
        "            value=0.9,  # Значение по умолчанию\n",
        "            step=0.1,  # Шаг изменения\n",
        "            label=\"Температура (креативность)\"  # Подпись\n",
        "        ),\n",
        "\n",
        "        # Слайдер для top-p фильтрации\n",
        "        gr.Slider(\n",
        "            0.5, 1.0,  # Диапазон\n",
        "            value=0.95,  # По умолчанию\n",
        "            step=0.05,  # Шаг\n",
        "            label=\"Top-p (разнообразие)\"  # Подпись\n",
        "        ),\n",
        "\n",
        "        # Выпадающий список для выбора количества beam'ов\n",
        "        gr.Dropdown(\n",
        "            choices=[1, 2, 3, 4, 5],  # Доступные варианты\n",
        "            value=3,  # Значение по умолчанию\n",
        "            label=\"Количество beam'ов\"  # Подпись\n",
        "        )\n",
        "    ],\n",
        "\n",
        "    # Настройка вывода (с поддержкой HTML)\n",
        "    outputs=gr.HTML(\n",
        "        label=\"Сгенерированный текст\"  # Подпись поля вывода\n",
        "    ),\n",
        "\n",
        "    # Заголовок интерфейса\n",
        "    title=\"Генератор текста\",\n",
        "\n",
        "    # Описание с HTML-разметкой\n",
        "    description=\"\"\"\n",
        "    <div style='margin-bottom: 15px;'>\n",
        "        Генерация текста на русском языке с помощью модели RuGPT-3 Large.<br>\n",
        "        Поэкспериментируйте с параметрами для разных результатов!\n",
        "    </div>\n",
        "    \"\"\",\n",
        "\n",
        "    # Примеры для быстрого тестирования\n",
        "    examples=[\n",
        "        # Каждый пример - список значений для всех input элементов\n",
        "        [\"В далеком будущем, когда человечество колонизировало Марс\", 150, 0.7, 0.9, 3],\n",
        "        [\"Философский вопрос: может ли искусственный интеллект\", 200, 0.8, 0.95, 4],\n",
        "        [\"Рецепт идеального борща:\", 100, 0.5, 0.85, 2]\n",
        "    ],\n",
        "\n",
        "    # Настройка темы интерфейса\n",
        "    theme=gr.themes.Default(\n",
        "        primary_hue=\"green\",  # Основной цвет (кнопки, акценты)\n",
        "        secondary_hue=\"teal\"  # Дополнительный цвет\n",
        "    ),\n",
        "\n",
        "    # Отключаем кнопку репортов\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "# Запускаем интерфейс\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "tBqvPahdDWeA",
        "outputId": "bf89d910-c39f-4052-d639-eb96842137ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f3d93b2e5a2c8518ae.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f3d93b2e5a2c8518ae.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Пример 3. Перевод текста**\n"
      ],
      "metadata": {
        "id": "bjjD5CCCHBrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODELS = {\n",
        "    \"Английский → Русский\": \"Helsinki-NLP/opus-mt-en-ru\",\n",
        "    \"Русский → Английский\": \"Helsinki-NLP/opus-mt-ru-en\",\n",
        "}\n",
        "\n",
        "loaded_models = {}\n",
        "\n",
        "def translate(text, direction):\n",
        "    if not text.strip():\n",
        "        return \"Введите текст для перевода\"\n",
        "\n",
        "    try:\n",
        "        if direction not in loaded_models:\n",
        "            loaded_models[direction] = pipeline(\n",
        "                \"translation\",\n",
        "                model=MODELS[direction]\n",
        "            )\n",
        "\n",
        "        result = loaded_models[direction](text)[0]['translation_text']\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Ошибка перевода: {str(e)}\"\n",
        "\n",
        "# Создаем интерфейс переводчика\n",
        "iface = gr.Interface(\n",
        "    # Основная функция, которая будет обрабатывать перевод\n",
        "    fn=translate,  # Функция должна принимать текст и направление перевода\n",
        "\n",
        "    # Входные элементы интерфейса\n",
        "    inputs=[\n",
        "        # Текстовое поле для ввода исходного текста\n",
        "        gr.Textbox(\n",
        "            lines=3,  # Высота текстового поля (3 строки)\n",
        "            placeholder=\"Введите текст для перевода...\",  # Подсказка в пустом поле\n",
        "            label=\"Исходный текст\"  # Надпись над полем ввода\n",
        "        ),\n",
        "\n",
        "        # Выпадающий список для выбора направления перевода\n",
        "        gr.Dropdown(\n",
        "            choices=list(MODELS.keys()),  # Варианты из словаря MODELS\n",
        "            value=\"Английский → Русский\",  # Значение по умолчанию\n",
        "            label=\"Направление перевода\"  # Подпись элемента\n",
        "        )\n",
        "    ],\n",
        "\n",
        "    # Выходное поле для перевода\n",
        "    outputs=gr.Textbox(\n",
        "        label=\"Перевод\",  # Надпись над полем вывода\n",
        "        lines=5  # Высота поля вывода (5 строк)\n",
        "    ),\n",
        "\n",
        "    # Заголовок интерфейса\n",
        "    title=\"Переводчик\",\n",
        "\n",
        "    # Примеры для быстрого тестирования\n",
        "    examples=[\n",
        "        # Первый пример - английский текст\n",
        "        [\"Hello world\", \"Английский → Русский\"],\n",
        "        # Второй пример - русский текст\n",
        "        [\"Привет мир\", \"Русский → Английский\"]\n",
        "    ],\n",
        "\n",
        "    # Отключаем кнопку \"пожаловаться\" (не используем систему репортов)\n",
        "    allow_flagging=\"never\",\n",
        "\n",
        "    # Настраиваем цветовую тему интерфейса\n",
        "    theme=gr.themes.Default(\n",
        "        primary_hue=\"blue\",  # Основной синий цвет для кнопок и акцентов\n",
        "        secondary_hue=\"gray\"  # Вторичный серый цвет\n",
        "    )\n",
        ")\n",
        "\n",
        "# Запускаем веб-интерфейс\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "yThPTRxyG_2Y",
        "outputId": "69c6f9b5-3ed3-4bae-84a1-e53e7695d9fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://403ca8e9963df720e3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://403ca8e9963df720e3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Пример 4. Заполнение пропусков**"
      ],
      "metadata": {
        "id": "Ey5Y4iIKJyBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODELS = {\n",
        "    \"Английский (BERT)\": {\n",
        "        \"name\": \"bert-base-uncased\",\n",
        "        \"pipeline\": None,\n",
        "        \"mask_token\": \"[MASK]\"\n",
        "    },\n",
        "    \"Русский (RuBERT)\": {\n",
        "        \"name\": \"DeepPavlov/rubert-base-cased\",\n",
        "        \"pipeline\": None,\n",
        "        \"mask_token\": \"[MASK]\"\n",
        "    },\n",
        "    \"Мультиязычный (XLM)\": {\n",
        "        \"name\": \"xlm-roberta-base\",\n",
        "        \"pipeline\": None,\n",
        "        \"mask_token\": \"<mask>\"\n",
        "    }\n",
        "}\n",
        "\n",
        "for model_name, config in MODELS.items():\n",
        "    try:\n",
        "        MODELS[model_name][\"pipeline\"] = pipeline(\n",
        "            \"fill-mask\",\n",
        "            model=config[\"name\"]\n",
        "        )\n",
        "        print(f\"{model_name} загружена\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка загрузки {model_name}: {str(e)}\")\n",
        "\n",
        "def predict_masked(text, model_choice):\n",
        "    if not text.strip():\n",
        "        return \"Введите текст с пропуском\"\n",
        "\n",
        "    config = MODELS.get(model_choice)\n",
        "    if not config or not config[\"pipeline\"]:\n",
        "        return \"Модель не загружена\"\n",
        "\n",
        "    mask = config[\"mask_token\"]\n",
        "    if mask not in text:\n",
        "        return f\"Вставьте '{mask}' в текст\"\n",
        "\n",
        "    try:\n",
        "        results = config[\"pipeline\"](text, top_k=5)\n",
        "        output = []\n",
        "        for i, res in enumerate(results, 1):\n",
        "            seq = res['sequence'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
        "            output.append(f\"{i}. {seq} (вероятность: {res['score']:.3f})\")\n",
        "        return \"\\n\".join(output)\n",
        "    except Exception as e:\n",
        "        return f\"Ошибка: {str(e)}\"\n",
        "\n",
        "examples = [\n",
        "    [\"The capital of France is [MASK].\", \"Английский (BERT)\"],\n",
        "    [\"Столица России - [MASK].\", \"Русский (RuBERT)\"],\n",
        "    [\"Paris is the <mask> of France.\", \"Мультиязычный (XLM)\"]\n",
        "]\n",
        "\n",
        "# Создаем интерфейс\n",
        "iface = gr.Interface(\n",
        "    # Основная функция обработки (принимает текст и выбранную модель)\n",
        "    fn=predict_masked,\n",
        "\n",
        "    # Входные элементы интерфейса\n",
        "    inputs=[\n",
        "        # Текстовое поле для ввода с пропуском\n",
        "        gr.Textbox(\n",
        "            lines=2,  # Высота в 2 строки\n",
        "            placeholder=\"Введите текст с [MASK] или <mask>...\",  # Подсказка\n",
        "            label=\"Текст с пропуском\"  # Надпись над полем\n",
        "        ),\n",
        "\n",
        "        # Выпадающий список для выбора модели\n",
        "        gr.Dropdown(\n",
        "            list(MODELS.keys()),  # Варианты из словаря MODELS\n",
        "            value=\"Английский (BERT)\",  # Модель по умолчанию\n",
        "            label=\"Выберите модель\"  # Подпись элемента\n",
        "        )\n",
        "    ],\n",
        "\n",
        "    # Выходное поле с результатами\n",
        "    outputs=gr.Textbox(\n",
        "        label=\"Топ-5 вариантов\",  # Заголовок поля вывода\n",
        "        lines=6  # Высота поля (6 строк)\n",
        "    ),\n",
        "\n",
        "    # Заголовок интерфейса\n",
        "    title=\"🔄 Универсальный заполнитель пропусков\",\n",
        "\n",
        "    # Описание под заголовком\n",
        "    description=\"Предзагруженные модели для английского, русского и мультиязычных текстов\",\n",
        "\n",
        "    # Примеры для быстрого тестирования\n",
        "    examples=examples,\n",
        "\n",
        "    # Настройка цветовой темы\n",
        "    theme=gr.themes.Soft(  # \"Мягкая\" тема\n",
        "        primary_hue=\"blue\",  # Основной синий цвет\n",
        "        secondary_hue=\"gray\"  # Вторичный серый цвет\n",
        "    )\n",
        ")\n",
        "\n",
        "# Запускаем веб-интерфейс\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "mza_jq9lJxPK",
        "outputId": "2f39203a-2b0e-48ec-d34d-3694bf652220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Английский (BERT) загружена\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Русский (RuBERT) загружена\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мультиязычный (XLM) загружена\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c9e3f12d637116b447.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c9e3f12d637116b447.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}